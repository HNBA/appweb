input {
  #stdin { codec => json }
  udp {
    port => {{ logstash_collectd_port }}
    buffer_size => 1452
    codec => collectd { }
  }
  beats {
    port => {{ logstash_port }}
  }
}




filter {
  #json {  source => "message" }
  

if "/var/log/kafka/kafkaServer-gc.log" in [source] {
   {% include "kafka-server-gc" %}
  } else if "/var/log/kafka/log-cleaner.log" in [source] {
   {% include "kafka-log-cleaner" %}
  } else if "/var/log/kafka/state-change.log" in [source] {
   {% include "kafka-state-change" %}
  } else if "/var/log/zookeeper/zookeeper.log" in [source] {
   {% include "zookeeper" %}
  } else if "/var/log/gateway/gateway.log" in [source] {
   {% include "gateway" %}
  } else if "/var/log/gateway-sftp/daemon.log" in [source] {
   {% include "gateway-sftp-daemon" %}
  } else if "/var/log/gateway-sftp/gateway-sftp.log" in [source] {
   {% include "gateway-sftp" %}
  } else if "/var/log/haproxy/haproxy.log" in [source] {
   {% include "haproxy" %}
  } else if "/var/log/elasticsearch/phenix-es.log" in [source] {
   {% include "phenix-es" %}
  } else  if "/var/log/auth.log" in [source] {
   {% include "authd" %}
  } else {
    mutate {
      add_field => { "date" => "%{@timestamp}" }
                }  
  }

  date {
     match => [ "date", "yyyy-MM-dd HH:mm:ss,S", "MMM dd HH:mm:ss", "MMM  d HH:mm:ss", "yyyy-MM-dd'T'HH:mm:ss.SZ", "yyyy-MM-dd'T'HH:mm:ss,S", "ISO8601"]
     remove_field => [ "date" ]
     target => "logdate"
  }
}




output {
    elasticsearch {
      hosts => {{ item.elasticsearch_hosts }}
      user =>  "admin"
      password => '{{ vault_ldap_admin_pw }}'
    }
    #stdout { codec => rubydebug }
}


